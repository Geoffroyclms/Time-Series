{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import quandl\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quandl.ApiConfig.api_key = \"ByAzesCp4TpPvjqYi4ay\" #Pour faire plus de 50 requetes par jours\n",
    "#start = datetime(2016,1,1)\n",
    "#end = datetime(2017,1,1)\n",
    "#s = \"CBS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL_Pred',\n",
       " 'ABT_Pred',\n",
       " 'ACN_Pred',\n",
       " 'ATVI_Pred',\n",
       " 'ADBE_Pred',\n",
       " 'AMD_Pred',\n",
       " 'GOOGL_Pred',\n",
       " 'GOOG_Pred',\n",
       " 'AMZN_Pred',\n",
       " 'AAL_Pred',\n",
       " 'BLK_Pred',\n",
       " 'CBS_Pred',\n",
       " 'MSFT_Pred',\n",
       " 'FB_Pred']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logo_all=['AAPL','ABT','ACN','ATVI','ADBE','AMD','GOOGL','GOOG','AMZN','AAL','BLK','CBS','MSFT','FB']\n",
    "logo=logo_all[1:]\n",
    "\n",
    "logo_pred=['AAPL_Pred']\n",
    "for l in logo:\n",
    "    logo_pred.append(l+'_Pred')\n",
    "    \n",
    "\n",
    "    \n",
    "logo_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies=pd.DataFrame()\n",
    "df_companies['logo']=logo_all\n",
    "df_companies['logo_pred']=logo_pred\n",
    "df_companies.to_csv(r\"C:\\Users\\Geoffroy\\Desktop\\IT\\Projet Supélec\\Data_quandl\\Liste_entreprise.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=pd.read_csv(r\"C:\\Users\\Geoffroy\\Desktop\\IT\\Projet Supélec\\Data_quandl\\Data_total.csv\")\n",
    "df=df_all[:-3] #Les data - les 3 à prédire !\n",
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>CBS</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>FB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>107.33</td>\n",
       "      <td>44.04</td>\n",
       "      <td>102.99</td>\n",
       "      <td>38.74</td>\n",
       "      <td>91.62</td>\n",
       "      <td>2.53</td>\n",
       "      <td>760.80</td>\n",
       "      <td>747.77</td>\n",
       "      <td>664.51</td>\n",
       "      <td>42.400</td>\n",
       "      <td>325.55</td>\n",
       "      <td>45.79</td>\n",
       "      <td>54.83</td>\n",
       "      <td>104.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>107.23</td>\n",
       "      <td>44.48</td>\n",
       "      <td>103.76</td>\n",
       "      <td>39.21</td>\n",
       "      <td>93.82</td>\n",
       "      <td>2.77</td>\n",
       "      <td>767.13</td>\n",
       "      <td>750.00</td>\n",
       "      <td>663.15</td>\n",
       "      <td>42.895</td>\n",
       "      <td>330.51</td>\n",
       "      <td>46.61</td>\n",
       "      <td>55.35</td>\n",
       "      <td>105.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2015-12-23</td>\n",
       "      <td>108.61</td>\n",
       "      <td>45.10</td>\n",
       "      <td>104.42</td>\n",
       "      <td>38.84</td>\n",
       "      <td>94.70</td>\n",
       "      <td>2.83</td>\n",
       "      <td>768.51</td>\n",
       "      <td>750.31</td>\n",
       "      <td>663.70</td>\n",
       "      <td>43.290</td>\n",
       "      <td>339.64</td>\n",
       "      <td>47.23</td>\n",
       "      <td>55.82</td>\n",
       "      <td>104.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>108.03</td>\n",
       "      <td>45.10</td>\n",
       "      <td>104.23</td>\n",
       "      <td>38.92</td>\n",
       "      <td>94.30</td>\n",
       "      <td>2.92</td>\n",
       "      <td>765.84</td>\n",
       "      <td>748.40</td>\n",
       "      <td>662.79</td>\n",
       "      <td>43.810</td>\n",
       "      <td>337.40</td>\n",
       "      <td>47.44</td>\n",
       "      <td>55.67</td>\n",
       "      <td>105.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>106.82</td>\n",
       "      <td>45.03</td>\n",
       "      <td>104.08</td>\n",
       "      <td>39.03</td>\n",
       "      <td>94.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>782.24</td>\n",
       "      <td>762.51</td>\n",
       "      <td>675.20</td>\n",
       "      <td>43.230</td>\n",
       "      <td>342.45</td>\n",
       "      <td>46.83</td>\n",
       "      <td>55.95</td>\n",
       "      <td>105.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>108.74</td>\n",
       "      <td>45.82</td>\n",
       "      <td>105.32</td>\n",
       "      <td>39.58</td>\n",
       "      <td>95.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>793.96</td>\n",
       "      <td>776.60</td>\n",
       "      <td>693.97</td>\n",
       "      <td>43.500</td>\n",
       "      <td>343.60</td>\n",
       "      <td>47.29</td>\n",
       "      <td>56.55</td>\n",
       "      <td>107.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>107.32</td>\n",
       "      <td>45.27</td>\n",
       "      <td>105.86</td>\n",
       "      <td>39.43</td>\n",
       "      <td>95.28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>790.30</td>\n",
       "      <td>771.00</td>\n",
       "      <td>689.07</td>\n",
       "      <td>42.800</td>\n",
       "      <td>342.05</td>\n",
       "      <td>46.76</td>\n",
       "      <td>56.31</td>\n",
       "      <td>106.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>105.26</td>\n",
       "      <td>44.91</td>\n",
       "      <td>104.50</td>\n",
       "      <td>38.71</td>\n",
       "      <td>93.94</td>\n",
       "      <td>2.87</td>\n",
       "      <td>778.01</td>\n",
       "      <td>758.88</td>\n",
       "      <td>675.89</td>\n",
       "      <td>42.350</td>\n",
       "      <td>340.52</td>\n",
       "      <td>47.13</td>\n",
       "      <td>55.48</td>\n",
       "      <td>104.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>105.35</td>\n",
       "      <td>42.93</td>\n",
       "      <td>101.83</td>\n",
       "      <td>37.62</td>\n",
       "      <td>91.97</td>\n",
       "      <td>2.77</td>\n",
       "      <td>759.44</td>\n",
       "      <td>741.84</td>\n",
       "      <td>636.99</td>\n",
       "      <td>40.910</td>\n",
       "      <td>333.10</td>\n",
       "      <td>46.65</td>\n",
       "      <td>54.80</td>\n",
       "      <td>102.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>102.71</td>\n",
       "      <td>42.92</td>\n",
       "      <td>102.36</td>\n",
       "      <td>37.14</td>\n",
       "      <td>92.34</td>\n",
       "      <td>2.75</td>\n",
       "      <td>761.53</td>\n",
       "      <td>742.58</td>\n",
       "      <td>633.79</td>\n",
       "      <td>40.520</td>\n",
       "      <td>333.96</td>\n",
       "      <td>46.12</td>\n",
       "      <td>55.05</td>\n",
       "      <td>102.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    AAPL    ABT     ACN   ATVI   ADBE   AMD   GOOGL    GOOG  \\\n",
       "244  2015-12-21  107.33  44.04  102.99  38.74  91.62  2.53  760.80  747.77   \n",
       "245  2015-12-22  107.23  44.48  103.76  39.21  93.82  2.77  767.13  750.00   \n",
       "246  2015-12-23  108.61  45.10  104.42  38.84  94.70  2.83  768.51  750.31   \n",
       "247  2015-12-24  108.03  45.10  104.23  38.92  94.30  2.92  765.84  748.40   \n",
       "248  2015-12-28  106.82  45.03  104.08  39.03  94.20  3.00  782.24  762.51   \n",
       "249  2015-12-29  108.74  45.82  105.32  39.58  95.33  3.00  793.96  776.60   \n",
       "250  2015-12-30  107.32  45.27  105.86  39.43  95.28  2.98  790.30  771.00   \n",
       "251  2015-12-31  105.26  44.91  104.50  38.71  93.94  2.87  778.01  758.88   \n",
       "252  2016-01-04  105.35  42.93  101.83  37.62  91.97  2.77  759.44  741.84   \n",
       "253  2016-01-05  102.71  42.92  102.36  37.14  92.34  2.75  761.53  742.58   \n",
       "\n",
       "       AMZN     AAL     BLK    CBS   MSFT      FB  \n",
       "244  664.51  42.400  325.55  45.79  54.83  104.77  \n",
       "245  663.15  42.895  330.51  46.61  55.35  105.51  \n",
       "246  663.70  43.290  339.64  47.23  55.82  104.63  \n",
       "247  662.79  43.810  337.40  47.44  55.67  105.02  \n",
       "248  675.20  43.230  342.45  46.83  55.95  105.93  \n",
       "249  693.97  43.500  343.60  47.29  56.55  107.26  \n",
       "250  689.07  42.800  342.05  46.76  56.31  106.22  \n",
       "251  675.89  42.350  340.52  47.13  55.48  104.66  \n",
       "252  636.99  40.910  333.10  46.65  54.80  102.22  \n",
       "253  633.79  40.520  333.96  46.12  55.05  102.73  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essayer avec une dataframe avec Data . Close Ent1, Close Ent2, Close Ent3, Close Ent4,.....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Geoffroy\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype float32 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "minmax = MinMaxScaler().fit(df.iloc[:, 1:].astype('float32'))\n",
    "df_log = minmax.transform(df.iloc[:, 1:].astype('float32'))\n",
    "df_log = pd.DataFrame(df_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idée :Faire le [:3] après le MinMaxScaller pour avoir les 3 derniers scaller aussi ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.199076</td>\n",
       "      <td>0.556837</td>\n",
       "      <td>0.828405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991005</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328587</td>\n",
       "      <td>0.576892</td>\n",
       "      <td>0.349271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.511532</td>\n",
       "      <td>0.849416</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>0.989050</td>\n",
       "      <td>0.804734</td>\n",
       "      <td>0.987673</td>\n",
       "      <td>0.980285</td>\n",
       "      <td>0.987961</td>\n",
       "      <td>0.290252</td>\n",
       "      <td>0.559037</td>\n",
       "      <td>0.327796</td>\n",
       "      <td>0.985240</td>\n",
       "      <td>0.920194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.084186</td>\n",
       "      <td>0.481878</td>\n",
       "      <td>0.796498</td>\n",
       "      <td>0.958630</td>\n",
       "      <td>0.936645</td>\n",
       "      <td>0.739645</td>\n",
       "      <td>0.946278</td>\n",
       "      <td>0.937617</td>\n",
       "      <td>0.955580</td>\n",
       "      <td>0.265608</td>\n",
       "      <td>0.541412</td>\n",
       "      <td>0.342788</td>\n",
       "      <td>0.934194</td>\n",
       "      <td>0.875572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.087157</td>\n",
       "      <td>0.318781</td>\n",
       "      <td>0.692607</td>\n",
       "      <td>0.906800</td>\n",
       "      <td>0.859601</td>\n",
       "      <td>0.680473</td>\n",
       "      <td>0.883732</td>\n",
       "      <td>0.877627</td>\n",
       "      <td>0.860007</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>0.455938</td>\n",
       "      <td>0.323339</td>\n",
       "      <td>0.892374</td>\n",
       "      <td>0.805778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317957</td>\n",
       "      <td>0.713230</td>\n",
       "      <td>0.883975</td>\n",
       "      <td>0.874071</td>\n",
       "      <td>0.668639</td>\n",
       "      <td>0.890771</td>\n",
       "      <td>0.880232</td>\n",
       "      <td>0.852145</td>\n",
       "      <td>0.165389</td>\n",
       "      <td>0.465845</td>\n",
       "      <td>0.301864</td>\n",
       "      <td>0.907749</td>\n",
       "      <td>0.820366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "249  0.199076  0.556837  0.828405  1.000000  0.991005  0.816568  1.000000   \n",
       "250  0.152195  0.511532  0.849416  0.992867  0.989050  0.804734  0.987673   \n",
       "251  0.084186  0.481878  0.796498  0.958630  0.936645  0.739645  0.946278   \n",
       "252  0.087157  0.318781  0.692607  0.906800  0.859601  0.680473  0.883732   \n",
       "253  0.000000  0.317957  0.713230  0.883975  0.874071  0.668639  0.890771   \n",
       "\n",
       "           7         8         9         10        11        12        13  \n",
       "249  1.000000  1.000000  0.328587  0.576892  0.349271  1.000000  0.949943  \n",
       "250  0.980285  0.987961  0.290252  0.559037  0.327796  0.985240  0.920194  \n",
       "251  0.937617  0.955580  0.265608  0.541412  0.342788  0.934194  0.875572  \n",
       "252  0.877627  0.860007  0.186747  0.455938  0.323339  0.892374  0.805778  \n",
       "253  0.880232  0.852145  0.165389  0.465845  0.301864  0.907749  0.820366  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 500\n",
    "dropout_rate = 0.7\n",
    "future_day = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000002394A5D1E48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Geoffroy\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "modelnn = Model(\n",
    "    0.01, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    ")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 avg loss: 0.014415911342948675\n",
      "epoch: 200 avg loss: 0.011466263150796295\n",
      "epoch: 300 avg loss: 0.010495326207019389\n",
      "epoch: 400 avg loss: 0.00872368274256587\n",
      "epoch: 500 avg loss: 0.009625736605376006\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "    total_loss = 0\n",
    "    for k in range(0, df_log.shape[0] - 1, timestamp):\n",
    "        index = min(k + timestamp, df_log.shape[0] -1)\n",
    "        batch_x = np.expand_dims(\n",
    "            df_log.iloc[k : index, :].values, axis = 0\n",
    "        )\n",
    "        batch_y = df_log.iloc[k + 1 : index + 1, :].values\n",
    "        last_state, _, loss = sess.run(\n",
    "            [modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "            feed_dict = {\n",
    "                modelnn.X: batch_x,\n",
    "                modelnn.Y: batch_y,\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        total_loss += loss\n",
    "    total_loss /= df_log.shape[0] // timestamp\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print('epoch:', i + 1, 'avg loss:', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predict = np.zeros((df_log.shape[0] + future_day, df_log.shape[1]))\n",
    "output_predict[0] = df_log.iloc[0]\n",
    "upper_b = (df_log.shape[0] // timestamp) * timestamp\n",
    "init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "for k in range(0, (df_log.shape[0] // timestamp) * timestamp, timestamp):\n",
    "    out_logits, last_state = sess.run(\n",
    "        [modelnn.logits, modelnn.last_state],\n",
    "        feed_dict = {\n",
    "            modelnn.X: np.expand_dims(\n",
    "                df_log.iloc[k : k + timestamp], axis = 0\n",
    "            ),\n",
    "            modelnn.hidden_layer: init_value,\n",
    "        },\n",
    "    )\n",
    "    init_value = last_state\n",
    "    output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "out_logits, last_state = sess.run(\n",
    "    [modelnn.logits, modelnn.last_state],\n",
    "    feed_dict = {\n",
    "        modelnn.X: np.expand_dims(df_log.iloc[upper_b:], axis = 0),\n",
    "        modelnn.hidden_layer: init_value,\n",
    "    },\n",
    ")\n",
    "init_value = last_state\n",
    "output_predict[upper_b + 1 : df_log.shape[0] + 1] = out_logits\n",
    "df_log.loc[df_log.shape[0]] = out_logits[-1]\n",
    "date_ori.append(date_ori[-1] + timedelta(days = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(future_day - 1):\n",
    "    out_logits, last_state = sess.run(\n",
    "        [modelnn.logits, modelnn.last_state],\n",
    "        feed_dict = {\n",
    "            modelnn.X: np.expand_dims(df_log.iloc[-timestamp:], axis = 0),\n",
    "            modelnn.hidden_layer: init_value,\n",
    "        },\n",
    "    )\n",
    "    init_value = last_state\n",
    "    output_predict[df_log.shape[0]] = out_logits[-1]\n",
    "    df_log.loc[df_log.shape[0]] = out_logits[-1]\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regarder si on peux directement faire les calculs de score, MSE sur les mesure entres 0 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = minmax.inverse_transform(output_predict)\n",
    "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Trading Day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL_Pred</th>\n",
       "      <th>ABT_Pred</th>\n",
       "      <th>ACN_Pred</th>\n",
       "      <th>ATVI_Pred</th>\n",
       "      <th>ADBE_Pred</th>\n",
       "      <th>AMD_Pred</th>\n",
       "      <th>GOOGL_Pred</th>\n",
       "      <th>GOOG_Pred</th>\n",
       "      <th>AMZN_Pred</th>\n",
       "      <th>AAL_Pred</th>\n",
       "      <th>BLK_Pred</th>\n",
       "      <th>CBS_Pred</th>\n",
       "      <th>MSFT_Pred</th>\n",
       "      <th>FB_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-73.524082</td>\n",
       "      <td>-3.195981</td>\n",
       "      <td>65.044697</td>\n",
       "      <td>5.827881</td>\n",
       "      <td>49.224533</td>\n",
       "      <td>2.520857</td>\n",
       "      <td>121.223985</td>\n",
       "      <td>194.057437</td>\n",
       "      <td>-663.238693</td>\n",
       "      <td>40.798665</td>\n",
       "      <td>145.304638</td>\n",
       "      <td>-0.334733</td>\n",
       "      <td>37.858610</td>\n",
       "      <td>-18.761325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>306.589018</td>\n",
       "      <td>245.068651</td>\n",
       "      <td>394.243311</td>\n",
       "      <td>11.393528</td>\n",
       "      <td>262.143543</td>\n",
       "      <td>-6.563217</td>\n",
       "      <td>-1457.218293</td>\n",
       "      <td>-1600.532009</td>\n",
       "      <td>-175.611286</td>\n",
       "      <td>-78.161966</td>\n",
       "      <td>1103.373147</td>\n",
       "      <td>396.277595</td>\n",
       "      <td>187.043876</td>\n",
       "      <td>266.826621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>4.996628</td>\n",
       "      <td>18.271296</td>\n",
       "      <td>444.697599</td>\n",
       "      <td>382.578691</td>\n",
       "      <td>539.763001</td>\n",
       "      <td>-6.936736</td>\n",
       "      <td>4674.088185</td>\n",
       "      <td>4270.858328</td>\n",
       "      <td>7250.370041</td>\n",
       "      <td>-383.900603</td>\n",
       "      <td>-176.860392</td>\n",
       "      <td>-202.704329</td>\n",
       "      <td>257.199079</td>\n",
       "      <td>716.336497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAPL_Pred    ABT_Pred    ACN_Pred   ATVI_Pred   ADBE_Pred  AMD_Pred  \\\n",
       "256  -73.524082   -3.195981   65.044697    5.827881   49.224533  2.520857   \n",
       "257  306.589018  245.068651  394.243311   11.393528  262.143543 -6.563217   \n",
       "258    4.996628   18.271296  444.697599  382.578691  539.763001 -6.936736   \n",
       "\n",
       "      GOOGL_Pred    GOOG_Pred    AMZN_Pred    AAL_Pred     BLK_Pred  \\\n",
       "256   121.223985   194.057437  -663.238693   40.798665   145.304638   \n",
       "257 -1457.218293 -1600.532009  -175.611286  -78.161966  1103.373147   \n",
       "258  4674.088185  4270.858328  7250.370041 -383.900603  -176.860392   \n",
       "\n",
       "       CBS_Pred   MSFT_Pred     FB_Pred  \n",
       "256   -0.334733   37.858610  -18.761325  \n",
       "257  396.277595  187.043876  266.826621  \n",
       "258 -202.704329  257.199079  716.336497  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred=pd.DataFrame(df_log)\n",
    "df_pred.columns=logo_pred\n",
    "df_pred.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>...</th>\n",
       "      <th>ADBE_Pred</th>\n",
       "      <th>AMD_Pred</th>\n",
       "      <th>GOOGL_Pred</th>\n",
       "      <th>GOOG_Pred</th>\n",
       "      <th>AMZN_Pred</th>\n",
       "      <th>AAL_Pred</th>\n",
       "      <th>BLK_Pred</th>\n",
       "      <th>CBS_Pred</th>\n",
       "      <th>MSFT_Pred</th>\n",
       "      <th>FB_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>100.70</td>\n",
       "      <td>42.56</td>\n",
       "      <td>102.16</td>\n",
       "      <td>36.79</td>\n",
       "      <td>91.02</td>\n",
       "      <td>2.505</td>\n",
       "      <td>759.33</td>\n",
       "      <td>743.62</td>\n",
       "      <td>632.65</td>\n",
       "      <td>...</td>\n",
       "      <td>94.403892</td>\n",
       "      <td>2.917860</td>\n",
       "      <td>794.352958</td>\n",
       "      <td>778.660509</td>\n",
       "      <td>661.267695</td>\n",
       "      <td>41.158033</td>\n",
       "      <td>327.898282</td>\n",
       "      <td>43.120488</td>\n",
       "      <td>57.344854</td>\n",
       "      <td>104.651667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>96.45</td>\n",
       "      <td>41.54</td>\n",
       "      <td>99.16</td>\n",
       "      <td>36.27</td>\n",
       "      <td>89.11</td>\n",
       "      <td>2.275</td>\n",
       "      <td>741.00</td>\n",
       "      <td>726.39</td>\n",
       "      <td>607.94</td>\n",
       "      <td>...</td>\n",
       "      <td>103.322109</td>\n",
       "      <td>4.633403</td>\n",
       "      <td>923.242789</td>\n",
       "      <td>910.181901</td>\n",
       "      <td>680.685575</td>\n",
       "      <td>35.568259</td>\n",
       "      <td>285.036624</td>\n",
       "      <td>26.691158</td>\n",
       "      <td>65.039900</td>\n",
       "      <td>108.637435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>96.96</td>\n",
       "      <td>40.67</td>\n",
       "      <td>98.20</td>\n",
       "      <td>35.71</td>\n",
       "      <td>87.85</td>\n",
       "      <td>2.140</td>\n",
       "      <td>730.91</td>\n",
       "      <td>714.47</td>\n",
       "      <td>607.05</td>\n",
       "      <td>...</td>\n",
       "      <td>49.224533</td>\n",
       "      <td>2.520857</td>\n",
       "      <td>121.223985</td>\n",
       "      <td>194.057437</td>\n",
       "      <td>-663.238693</td>\n",
       "      <td>40.798665</td>\n",
       "      <td>145.304638</td>\n",
       "      <td>-0.334733</td>\n",
       "      <td>37.858610</td>\n",
       "      <td>-18.761325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    AAPL    ABT     ACN   ATVI   ADBE    AMD   GOOGL    GOOG  \\\n",
       "254  2016-01-06  100.70  42.56  102.16  36.79  91.02  2.505  759.33  743.62   \n",
       "255  2016-01-07   96.45  41.54   99.16  36.27  89.11  2.275  741.00  726.39   \n",
       "256  2016-01-08   96.96  40.67   98.20  35.71  87.85  2.140  730.91  714.47   \n",
       "\n",
       "       AMZN  ...   ADBE_Pred  AMD_Pred  GOOGL_Pred   GOOG_Pred   AMZN_Pred  \\\n",
       "254  632.65  ...   94.403892  2.917860  794.352958  778.660509  661.267695   \n",
       "255  607.94  ...  103.322109  4.633403  923.242789  910.181901  680.685575   \n",
       "256  607.05  ...   49.224533  2.520857  121.223985  194.057437 -663.238693   \n",
       "\n",
       "      AAL_Pred    BLK_Pred   CBS_Pred  MSFT_Pred     FB_Pred  \n",
       "254  41.158033  327.898282  43.120488  57.344854  104.651667  \n",
       "255  35.568259  285.036624  26.691158  65.039900  108.637435  \n",
       "256  40.798665  145.304638  -0.334733  37.858610  -18.761325  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=df_all.join(df_pred)\n",
    "df_final.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAL</th>\n",
       "      <th>...</th>\n",
       "      <th>ADBE_Pred</th>\n",
       "      <th>AMD_Pred</th>\n",
       "      <th>GOOGL_Pred</th>\n",
       "      <th>GOOG_Pred</th>\n",
       "      <th>AMZN_Pred</th>\n",
       "      <th>AAL_Pred</th>\n",
       "      <th>BLK_Pred</th>\n",
       "      <th>CBS_Pred</th>\n",
       "      <th>MSFT_Pred</th>\n",
       "      <th>FB_Pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>100.70</td>\n",
       "      <td>42.56</td>\n",
       "      <td>102.16</td>\n",
       "      <td>36.79</td>\n",
       "      <td>91.02</td>\n",
       "      <td>2.505</td>\n",
       "      <td>759.33</td>\n",
       "      <td>743.62</td>\n",
       "      <td>632.65</td>\n",
       "      <td>41.23</td>\n",
       "      <td>...</td>\n",
       "      <td>94.403892</td>\n",
       "      <td>2.917860</td>\n",
       "      <td>794.352958</td>\n",
       "      <td>778.660509</td>\n",
       "      <td>661.267695</td>\n",
       "      <td>41.158033</td>\n",
       "      <td>327.898282</td>\n",
       "      <td>43.120488</td>\n",
       "      <td>57.344854</td>\n",
       "      <td>104.651667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>96.45</td>\n",
       "      <td>41.54</td>\n",
       "      <td>99.16</td>\n",
       "      <td>36.27</td>\n",
       "      <td>89.11</td>\n",
       "      <td>2.275</td>\n",
       "      <td>741.00</td>\n",
       "      <td>726.39</td>\n",
       "      <td>607.94</td>\n",
       "      <td>40.45</td>\n",
       "      <td>...</td>\n",
       "      <td>103.322109</td>\n",
       "      <td>4.633403</td>\n",
       "      <td>923.242789</td>\n",
       "      <td>910.181901</td>\n",
       "      <td>680.685575</td>\n",
       "      <td>35.568259</td>\n",
       "      <td>285.036624</td>\n",
       "      <td>26.691158</td>\n",
       "      <td>65.039900</td>\n",
       "      <td>108.637435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>96.96</td>\n",
       "      <td>40.67</td>\n",
       "      <td>98.20</td>\n",
       "      <td>35.71</td>\n",
       "      <td>87.85</td>\n",
       "      <td>2.140</td>\n",
       "      <td>730.91</td>\n",
       "      <td>714.47</td>\n",
       "      <td>607.05</td>\n",
       "      <td>40.37</td>\n",
       "      <td>...</td>\n",
       "      <td>49.224533</td>\n",
       "      <td>2.520857</td>\n",
       "      <td>121.223985</td>\n",
       "      <td>194.057437</td>\n",
       "      <td>-663.238693</td>\n",
       "      <td>40.798665</td>\n",
       "      <td>145.304638</td>\n",
       "      <td>-0.334733</td>\n",
       "      <td>37.858610</td>\n",
       "      <td>-18.761325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL    ABT     ACN   ATVI   ADBE    AMD   GOOGL    GOOG  \\\n",
       "Date                                                                     \n",
       "2016-01-06  100.70  42.56  102.16  36.79  91.02  2.505  759.33  743.62   \n",
       "2016-01-07   96.45  41.54   99.16  36.27  89.11  2.275  741.00  726.39   \n",
       "2016-01-08   96.96  40.67   98.20  35.71  87.85  2.140  730.91  714.47   \n",
       "\n",
       "              AMZN    AAL  ...   ADBE_Pred  AMD_Pred  GOOGL_Pred   GOOG_Pred  \\\n",
       "Date                       ...                                                 \n",
       "2016-01-06  632.65  41.23  ...   94.403892  2.917860  794.352958  778.660509   \n",
       "2016-01-07  607.94  40.45  ...  103.322109  4.633403  923.242789  910.181901   \n",
       "2016-01-08  607.05  40.37  ...   49.224533  2.520857  121.223985  194.057437   \n",
       "\n",
       "             AMZN_Pred   AAL_Pred    BLK_Pred   CBS_Pred  MSFT_Pred  \\\n",
       "Date                                                                  \n",
       "2016-01-06  661.267695  41.158033  327.898282  43.120488  57.344854   \n",
       "2016-01-07  680.685575  35.568259  285.036624  26.691158  65.039900   \n",
       "2016-01-08 -663.238693  40.798665  145.304638  -0.334733  37.858610   \n",
       "\n",
       "               FB_Pred  \n",
       "Date                    \n",
       "2016-01-06  104.651667  \n",
       "2016-01-07  108.637435  \n",
       "2016-01-08  -18.761325  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred=df_final[-3:]\n",
    "df_pred=df_pred.set_index('Date')\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(r\"C:\\Users\\Geoffroy\\Desktop\\IT\\Projet Supélec\\Data_quandl\\LSTM_All_and_Pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
